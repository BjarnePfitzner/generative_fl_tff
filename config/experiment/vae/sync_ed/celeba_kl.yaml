# @package _global_

defaults:
  - override /model: vae
  - override /dataset: celeba
  - override /evaluation: development
  - override /differential_privacy: disabled
  - override /training/vae_loss_fn: kl_loss
  - override /training/early_stopping:
      - accuracy
      - fid

experiment_name: vae_sync_ed_celeba

training:
  total_rounds: 100
  aggregation_step_optimizer:
    type: SGD
    lr: 1.0
    momentum: 0.0
  client_optimizer:
    type: Adam
    lr: 0.0005
  vae_loss_fn:
    kl_beta_warmup: 0
    kl_beta: 0.01
  clients_per_round: 0.01
  local_epochs: 10
  batch_size: 8

evaluation:
  run_fid_eval: True
  plot_l2_norms: False
  rounds_per_eval: 20

model:
  type: sync_ed
  module: dp2_ccvae
  latent_dim: 8
  output_activation_fn: sigmoid


hydra:
  sweeper:
    params:
      model.latent_dim:
        - 2
        - 8
      training.batch_size:
        - 10
        - 20
        - 30
      training.local_epochs:
        - 1
        - 5
        - 10
      training.clients_per_round:
        - 0.01
        - 0.05
        - 0.1
      training.client_optimizer.lr:
        - 0.00001
        - 0.0001
        - 0.001
        - 0.01
      training.vae_loss_fn.kl_beta:
        - 0.01
        - 0.1
      training.aggregation_step_optimizer.momentum:
        - 0.0
        - 0.5
        - 0.9
